{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T01:51:24.832772Z",
     "start_time": "2019-10-14T01:51:24.805738Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T01:51:26.042046Z",
     "start_time": "2019-10-14T01:51:25.685618Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Investigation into Flight Delays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The flights dataset\n",
    "\n",
    "The department of transportation has all flight delays for listed years on their [website](https://catalog.data.gov/dataset/airline-on-time-performance-and-causes-of-flight-delays-on-time-data). There are data for the years 1987 - 2018. See the description of columns in `data/columns.txt`.\n",
    "\n",
    "This project will look at a single year (2015) to keep the analysis \"simple\", which is available at the URL below (*NOT* on the data.gov site).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the datasets\n",
    "\n",
    "**Step 1**\n",
    "\n",
    "The flights dataset for 2015 is not small (~600MB). While I could likely load the entire dataset into Pandas on my laptop, if I wanted to work with more than one year, this would quickly become difficult (the data is available for 1987-2018). Therefore, I will filter down the dataset into two smaller files without ever reading the larger dataset fully into memory. We are going to create two smaller datasets:\n",
    "\n",
    "1. All flights arriving or departing from San Diego International Airport in 2015.\n",
    "2. All flights flown by either JetBlue or Southwest Airline in 2015.\n",
    "\n",
    "---\n",
    "\n",
    "To do this, we are going to use the `chunksize=N` keyword in Pandas `read_csv` to read the flights dataset in blocks of `N` lines. When we use this keyword argument, `pd.read_csv(fp, chunksize=N)` becomes a *iterator* that iterates through dataframes of length N until we have reached the end of the dataset. A typical pattern looks like:\n",
    "```\n",
    "L = pd.read_csv(filepath, chunksize=1000)\n",
    "for df in L:\n",
    "    process(df)\n",
    "```\n",
    "Where each `df` is a dataframe of length 1000. \n",
    "\n",
    "The processing we are going to do is:\n",
    "1. Iterate through the dataset, chunk-by-chunk,\n",
    "2. Filtering out rows of each chunk\n",
    "3. Incrementally add to a filtered csv file (since the data is perhaps too big to keep in memory). Keep in mind, if you want to keep writing to the same file, the mode='a' keyword in the `.to_csv` method can be helpful when calling it in the loop (a stands for 'append')\n",
    "\n",
    "---\n",
    "\n",
    "Write two functions that create the datasets below, using the 'chunking' pattern described above. Your functions should use `chunksize` of 10000.\n",
    "1. `get_san` which takes in a filepath containing all flights and an filepath where filtered dataset #1 is written. The function should return `None`.\n",
    "1. `get_jb_sw` which takes in a filepath containing all flights and an filepath where filtered dataset #2 is written. The function should return `None`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_SAN(df):\n",
    "    ori = df[df['ORIGIN_AIRPORT'] == 'SAN']\n",
    "    dest = df[df['DESTINATION_AIRPORT'] == 'SAN']\n",
    "    return ori.append(dest)\n",
    "\n",
    "def get_san(infp, outfp):\n",
    "    \"\"\"\n",
    "    get_san takes in a filepath containing all flights and a filepath where\n",
    "    filtered dataset #1 is written (that is, all flights arriving or departing\n",
    "    from San Diego International Airport in 2015).\n",
    "    The function should return None.\n",
    "    \"\"\"\n",
    "    result = pd.DataFrame()\n",
    "    L = pd.read_csv(infp, chunksize=10000)\n",
    "    for df in L:\n",
    "        result = pd.concat([process_SAN(df), result])\n",
    "    result.to_csv(outfp, index=False)\n",
    "\n",
    "def process_airlines(df):\n",
    "    B6 = df[df['AIRLINE'] == 'B6']\n",
    "    JBU = df[df['AIRLINE'] == 'JBU']\n",
    "    WN = df[df['AIRLINE'] == 'WN']\n",
    "    SWA = df[df['AIRLINE'] == 'SWA']\n",
    "    return B6.append(JBU).append(WN).append(SWA)\n",
    "    \n",
    "def get_sw_jb(infp, outfp):\n",
    "    \"\"\"\n",
    "    get_sw_jb takes in a filepath containing all flights and a filepath where\n",
    "    filtered dataset #2 is written (that is, all flights flown by either\n",
    "    JetBlue or Southwest Airline in 2015).\n",
    "    The function should return None.\n",
    "    \"\"\"\n",
    "    result = pd.DataFrame()\n",
    "    L = pd.read_csv(infp, chunksize=10000)\n",
    "    for df in L:\n",
    "        result = pd.concat([process_airlines(df), result])\n",
    "    result.to_csv(outfp, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 31)\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "infp = os.path.join('data', 'flights.test')\n",
    "outfp = os.path.join('data', 'santest.tmp')\n",
    "get_san(infp, outfp)\n",
    "df = pd.read_csv(outfp)\n",
    "print(df.shape)\n",
    "#     (53, 31)\n",
    "os.remove(outfp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73, 31)\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "infp = os.path.join('data', 'flights.test')\n",
    "outfp = os.path.join('data', 'jbswtest.tmp')\n",
    "get_sw_jb(infp, outfp)\n",
    "df = pd.read_csv(outfp)\n",
    "print(df.shape)\n",
    "#     (73, 31)\n",
    "os.remove(outfp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>FLIGHT_NUMBER</th>\n",
       "      <th>TAIL_NUMBER</th>\n",
       "      <th>ORIGIN_AIRPORT</th>\n",
       "      <th>DESTINATION_AIRPORT</th>\n",
       "      <th>SCHEDULED_DEPARTURE</th>\n",
       "      <th>...</th>\n",
       "      <th>ARRIVAL_TIME</th>\n",
       "      <th>ARRIVAL_DELAY</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>CANCELLATION_REASON</th>\n",
       "      <th>AIR_SYSTEM_DELAY</th>\n",
       "      <th>SECURITY_DELAY</th>\n",
       "      <th>AIRLINE_DELAY</th>\n",
       "      <th>LATE_AIRCRAFT_DELAY</th>\n",
       "      <th>WEATHER_DELAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>B6</td>\n",
       "      <td>19</td>\n",
       "      <td>N584JB</td>\n",
       "      <td>BOS</td>\n",
       "      <td>SAN</td>\n",
       "      <td>1629</td>\n",
       "      <td>...</td>\n",
       "      <td>2000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>B6</td>\n",
       "      <td>190</td>\n",
       "      <td>N648JB</td>\n",
       "      <td>SAN</td>\n",
       "      <td>JFK</td>\n",
       "      <td>1252</td>\n",
       "      <td>...</td>\n",
       "      <td>2122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>B6</td>\n",
       "      <td>584</td>\n",
       "      <td>N613JB</td>\n",
       "      <td>MCO</td>\n",
       "      <td>JFK</td>\n",
       "      <td>940</td>\n",
       "      <td>...</td>\n",
       "      <td>1211</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>B6</td>\n",
       "      <td>462</td>\n",
       "      <td>N639JB</td>\n",
       "      <td>SJU</td>\n",
       "      <td>BOS</td>\n",
       "      <td>1153</td>\n",
       "      <td>...</td>\n",
       "      <td>1548</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>B6</td>\n",
       "      <td>1386</td>\n",
       "      <td>N216JB</td>\n",
       "      <td>12478</td>\n",
       "      <td>14576</td>\n",
       "      <td>1259</td>\n",
       "      <td>...</td>\n",
       "      <td>1409</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR  MONTH  DAY  DAY_OF_WEEK AIRLINE  FLIGHT_NUMBER TAIL_NUMBER  \\\n",
       "0  2015      8   21            5      B6             19      N584JB   \n",
       "1  2015      6   24            3      B6            190      N648JB   \n",
       "2  2015      3    3            2      B6            584      N613JB   \n",
       "3  2015      6    2            2      B6            462      N639JB   \n",
       "4  2015     10   26            1      B6           1386      N216JB   \n",
       "\n",
       "  ORIGIN_AIRPORT DESTINATION_AIRPORT  SCHEDULED_DEPARTURE  ...  ARRIVAL_TIME  \\\n",
       "0            BOS                 SAN                 1629  ...          2000   \n",
       "1            SAN                 JFK                 1252  ...          2122   \n",
       "2            MCO                 JFK                  940  ...          1211   \n",
       "3            SJU                 BOS                 1153  ...          1548   \n",
       "4          12478               14576                 1259  ...          1409   \n",
       "\n",
       "   ARRIVAL_DELAY  DIVERTED  CANCELLED  CANCELLATION_REASON  AIR_SYSTEM_DELAY  \\\n",
       "0           27.0     False      False                  NaN               0.0   \n",
       "1            0.0     False      False                  NaN               NaN   \n",
       "2           -2.0     False      False                  NaN               NaN   \n",
       "3          -12.0     False      False                  NaN               NaN   \n",
       "4           -7.0     False      False                  NaN               NaN   \n",
       "\n",
       "   SECURITY_DELAY  AIRLINE_DELAY  LATE_AIRCRAFT_DELAY  WEATHER_DELAY  \n",
       "0             0.0           27.0                  0.0            0.0  \n",
       "1             NaN            NaN                  NaN            NaN  \n",
       "2             NaN            NaN                  NaN            NaN  \n",
       "3             NaN            NaN                  NaN            NaN  \n",
       "4             NaN            NaN                  NaN            NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flight Delays to/from San Diego\n",
    "\n",
    "The department of transportation has all flight delays for listed years on their [website](https://catalog.data.gov/dataset/airline-on-time-performance-and-causes-of-flight-delays-on-time-data). \n",
    "\n",
    "The zip file at the [URL](https://dsc80-fa19-data.s3-us-west-2.amazonaws.com/project02/flight-delays.zip) contains a file `to_from_san.csv` that consists of all flights either to or from SAN (San Diego) in 2015 -- i.e. the output of step 1. This dataset should match the dataset that your code returned in question 1.\n",
    "\n",
    "Read in `to_from_san.csv` using `read_csv` and inspect the dataframe for an initial assessment about the data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T01:51:26.403770Z",
     "start_time": "2019-10-14T01:51:26.045071Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "to_from_san_filepath = os.path.join('data', 'to_from_san.csv')\n",
    "flights = pd.read_csv(to_from_san_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>FLIGHT_NUMBER</th>\n",
       "      <th>TAIL_NUMBER</th>\n",
       "      <th>ORIGIN_AIRPORT</th>\n",
       "      <th>DESTINATION_AIRPORT</th>\n",
       "      <th>SCHEDULED_DEPARTURE</th>\n",
       "      <th>...</th>\n",
       "      <th>ARRIVAL_TIME</th>\n",
       "      <th>ARRIVAL_DELAY</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>CANCELLATION_REASON</th>\n",
       "      <th>AIR_SYSTEM_DELAY</th>\n",
       "      <th>SECURITY_DELAY</th>\n",
       "      <th>AIRLINE_DELAY</th>\n",
       "      <th>LATE_AIRCRAFT_DELAY</th>\n",
       "      <th>WEATHER_DELAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>DL</td>\n",
       "      <td>978</td>\n",
       "      <td>N693DL</td>\n",
       "      <td>SAN</td>\n",
       "      <td>SLC</td>\n",
       "      <td>615</td>\n",
       "      <td>...</td>\n",
       "      <td>906.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>OO</td>\n",
       "      <td>5608</td>\n",
       "      <td>N930SW</td>\n",
       "      <td>SAN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>615</td>\n",
       "      <td>...</td>\n",
       "      <td>702.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>WN</td>\n",
       "      <td>823</td>\n",
       "      <td>N7707C</td>\n",
       "      <td>SAN</td>\n",
       "      <td>BWI</td>\n",
       "      <td>620</td>\n",
       "      <td>...</td>\n",
       "      <td>1352.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>WN</td>\n",
       "      <td>603</td>\n",
       "      <td>N461WN</td>\n",
       "      <td>SAN</td>\n",
       "      <td>MDW</td>\n",
       "      <td>620</td>\n",
       "      <td>...</td>\n",
       "      <td>1201.0</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>UA</td>\n",
       "      <td>1192</td>\n",
       "      <td>N69804</td>\n",
       "      <td>SAN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>620</td>\n",
       "      <td>...</td>\n",
       "      <td>936.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR  MONTH  DAY  DAY_OF_WEEK AIRLINE  FLIGHT_NUMBER TAIL_NUMBER  \\\n",
       "0  2015      1    1            4      DL            978      N693DL   \n",
       "1  2015      1    1            4      OO           5608      N930SW   \n",
       "2  2015      1    1            4      WN            823      N7707C   \n",
       "3  2015      1    1            4      WN            603      N461WN   \n",
       "4  2015      1    1            4      UA           1192      N69804   \n",
       "\n",
       "  ORIGIN_AIRPORT DESTINATION_AIRPORT  SCHEDULED_DEPARTURE  ...  ARRIVAL_TIME  \\\n",
       "0            SAN                 SLC                  615  ...         906.0   \n",
       "1            SAN                 LAX                  615  ...         702.0   \n",
       "2            SAN                 BWI                  620  ...        1352.0   \n",
       "3            SAN                 MDW                  620  ...        1201.0   \n",
       "4            SAN                 DEN                  620  ...         936.0   \n",
       "\n",
       "   ARRIVAL_DELAY  DIVERTED  CANCELLED  CANCELLATION_REASON  AIR_SYSTEM_DELAY  \\\n",
       "0          -10.0         0          0                  NaN               NaN   \n",
       "1           -5.0         0          0                  NaN               NaN   \n",
       "2          -23.0         0          0                  NaN               NaN   \n",
       "3          -29.0         0          0                  NaN               NaN   \n",
       "4           -9.0         0          0                  NaN               NaN   \n",
       "\n",
       "   SECURITY_DELAY  AIRLINE_DELAY  LATE_AIRCRAFT_DELAY  WEATHER_DELAY  \n",
       "0             NaN            NaN                  NaN            NaN  \n",
       "1             NaN            NaN                  NaN            NaN  \n",
       "2             NaN            NaN                  NaN            NaN  \n",
       "3             NaN            NaN                  NaN            NaN  \n",
       "4             NaN            NaN                  NaN            NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the data types of the columns\n",
    "\n",
    "**Step 2**:\n",
    "\n",
    "* First, classify the *kind* of data each column contains. Create a function `data_kinds` of zero variables which outputs a (hard-coded) dictionary of data kinds, keyed by column name, with values `Q`, `O`, `N` (for 'Quantitative', 'Ordinal', or 'Nominal').\n",
    "\n",
    "* Second, decide the best data *type* for each column. Create a function `data_types` of zero variables which outputs a (hard-coded) dictionary of data types, keyed by column name, with values `str`, `int`, `float`, `bool`. \n",
    "\n",
    "*Remark 1*: A column which *should* be `int`s, but contains `NaN`, *must* be a float column. See Lecture 2 notes an explanation of `NaN` and data-types.\n",
    "\n",
    "*Remark 2*: As with real data, some data processing decisions may be ambiguous here. Make a best decision using the information available to you. It may be helpful to (re)read the relevant [section of the textbook](https://afraenkel.github.io/practical-data-science/03/kinds-of-data.html). \n",
    "* Certain answers *may* have more than one correct answer (in these cases, more than one choice gets full credit),\n",
    "* All answers will be graded for partial credit (some wrong answers are more wrong than other).\n",
    "There are many columns, so don't worry about the correctness of any given one; do make sure you are thinking about what's contained in a column critically!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_kinds():\n",
    "    \"\"\"\n",
    "    data_kinds outputs a (hard-coded) dictionary of data kinds, keyed by column\n",
    "    name, with values Q, O, N (for 'Quantitative', 'Ordinal', or 'Nominal').\n",
    "\n",
    "    :Example:\n",
    "    >>> out = data_kinds()\n",
    "    >>> isinstance(out, dict)\n",
    "    True\n",
    "    >>> set(out.values()) == {'O', 'N', 'Q'}\n",
    "    True\n",
    "    \"\"\"\n",
    "\n",
    "    return {'YEAR': 'Q', 'MONTH': 'Q', 'DAY': 'Q', 'DAY_OF_WEEK': 'Q', 'AIRLINE': 'N', 'FLIGHT_NUMBER': 'N',\n",
    "       'TAIL_NUMBER': 'Q', 'ORIGIN_AIRPORT': 'N', 'DESTINATION_AIRPORT': 'N',\n",
    "       'SCHEDULED_DEPARTURE': 'Q', 'DEPARTURE_TIME': 'Q', 'DEPARTURE_DELAY': 'Q', 'TAXI_OUT': 'Q',\n",
    "       'WHEELS_OFF': 'Q', 'SCHEDULED_TIME': 'Q', 'ELAPSED_TIME': 'Q', 'AIR_TIME': 'Q', 'DISTANCE': 'Q',\n",
    "       'WHEELS_ON': 'Q', 'TAXI_IN': 'Q', 'SCHEDULED_ARRIVAL': 'Q', 'ARRIVAL_TIME': 'Q',\n",
    "       'ARRIVAL_DELAY': 'Q', 'DIVERTED': 'O', 'CANCELLED': 'O', 'CANCELLATION_REASON': 'O',\n",
    "       'AIR_SYSTEM_DELAY': 'Q', 'SECURITY_DELAY': 'Q', 'AIRLINE_DELAY': 'Q',\n",
    "       'LATE_AIRCRAFT_DELAY': 'Q', 'WEATHER_DELAY': 'Q'}\n",
    "\n",
    "\n",
    "def data_types():\n",
    "    \"\"\"\n",
    "    data_types outputs a (hard-coded) dictionary of data types, keyed by column\n",
    "    name, with values str, int, float.\n",
    "\n",
    "    :Example:\n",
    "    >>> out = data_types()\n",
    "    >>> isinstance(out, dict)\n",
    "    True\n",
    "    >>> set(out.values()) == {'int', 'str', 'float', 'bool'}\n",
    "    True\n",
    "    \"\"\"\n",
    "\n",
    "    return {'YEAR': 'int', 'MONTH': 'int', 'DAY': 'int', 'DAY_OF_WEEK': 'int', 'AIRLINE': 'str', 'FLIGHT_NUMBER': 'int',\n",
    "       'TAIL_NUMBER': 'str', 'ORIGIN_AIRPORT': 'str', 'DESTINATION_AIRPORT': 'str',\n",
    "       'SCHEDULED_DEPARTURE': 'int', 'DEPARTURE_TIME': 'float', 'DEPARTURE_DELAY': 'float', 'TAXI_OUT': 'float',\n",
    "       'WHEELS_OFF': 'float', 'SCHEDULED_TIME': 'int', 'ELAPSED_TIME': 'float', 'AIR_TIME': 'float', 'DISTANCE': 'int',\n",
    "       'WHEELS_ON': 'float', 'TAXI_IN': 'float', 'SCHEDULED_ARRIVAL': 'int', 'ARRIVAL_TIME': 'float',\n",
    "       'ARRIVAL_DELAY': 'float', 'DIVERTED': 'bool', 'CANCELLED': 'bool', 'CANCELLATION_REASON': 'str',\n",
    "       'AIR_SYSTEM_DELAY': 'float', 'SECURITY_DELAY': 'float', 'AIRLINE_DELAY': 'float',\n",
    "       'LATE_AIRCRAFT_DELAY': 'float', 'WEATHER_DELAY': 'float'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "\n",
    "out = data_kinds()\n",
    "print(isinstance(out, dict))\n",
    "#     True\n",
    "set(out.values()) == {'O', 'N', 'Q'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2\n",
    "out = data_types()\n",
    "print(isinstance(out, dict))\n",
    "#     True\n",
    "set(out.values()) == {'int', 'str', 'float', 'bool'}\n",
    "#     True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the typed flights data\n",
    "\n",
    "Read in the flights data using your dictionary of data-types in `read_csv`. This both speeds up parsing, as well as gives you the correct data-types upon reading (which columns would pandas *parse incorrectly* if you didn't use a `dtype` dictionary?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T01:51:26.410356Z",
     "start_time": "2019-10-14T01:51:24.819Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "dtypes = proj.data_types()\n",
    "flights = pd.read_csv(to_from_san_filepath, dtype=dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3 (Basic Stats):**\n",
    "\n",
    "Define a function `basic_stats` that takes `flights` and outputs a dataframe that contains statistics for flights arriving/departing for SAN. That is, the output should have two rows, indexed by `ARRIVING` and `DEPARTING`, and have the following columns:\n",
    "\n",
    "1. number of arriving/departing flights to/from SAN (`count`).\n",
    "2. mean flight (arrival) delay of arriving/departing flights to/from SAN (`mean_delay`).\n",
    "3. median flight (arrival) delay of arriving/departing flights to/from SAN (`median_delay`).\n",
    "4. the airline code of the airline with the longest flight (arrival) delay among all flights arriving/departing to/from SAN (`airline`).\n",
    "5. a list of the three months with the greatest number of arriving/departing flights to/from SAN, sorted from greatest to least (`top_months`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_stats(flights):\n",
    "    \"\"\"\n",
    "    basic_stats takes flights and outputs a dataframe that contains statistics\n",
    "    for flights arriving/departing for SAN.\n",
    "    That is, the output should have have two rows, indexed by ARRIVING and\n",
    "    DEPARTING, and have the following columns:\n",
    "\n",
    "    * number of arriving/departing flights to/from SAN (count).\n",
    "    * mean flight (arrival) delay of arriving/departing flights to/from SAN\n",
    "      (mean_delay).\n",
    "    * median flight (arrival) delay of arriving/departing flights to/from SAN\n",
    "      (median_delay).\n",
    "    * the airline code of the airline with the longest flight (arrival) delay\n",
    "      among all flights arriving/departing to/from SAN (airline).\n",
    "    * a list of the three months with the greatest number of arriving/departing\n",
    "      flights to/from SAN, sorted from greatest to least (top_months).\n",
    "\n",
    "    \"\"\"\n",
    "    departing = flights[flights['ORIGIN_AIRPORT']=='SAN']\n",
    "    arriving = flights[flights['DESTINATION_AIRPORT']=='SAN']\n",
    "    arr_count = arriving.shape[0]\n",
    "    dep_count = departing.shape[0]\n",
    "    arr_mean = np.nanmean(arriving['ARRIVAL_DELAY'])\n",
    "    dep_mean = np.nanmean(departing['ARRIVAL_DELAY'])\n",
    "    arr_median = np.nanmedian(arriving['ARRIVAL_DELAY'])\n",
    "    dep_median = np.nanmedian(departing['ARRIVAL_DELAY'])\n",
    "    arr_airling = arriving[arriving['ARRIVAL_DELAY'] == np.max(arriving['ARRIVAL_DELAY'])]['AIRLINE'].values[0]\n",
    "    dep_airling = departing[departing['ARRIVAL_DELAY'] == np.max(departing['ARRIVAL_DELAY'])]['AIRLINE'].values[0]\n",
    "    arr_months = arriving.groupby(\"MONTH\", as_index=False).count().sort_values('YEAR', ascending=False)['MONTH'].values[:3].tolist()\n",
    "    dep_months = departing.groupby(\"MONTH\", as_index=False).count().sort_values('YEAR', ascending=False)['MONTH'].values[:3].tolist()\n",
    "    data = {'count':[arr_count, dep_count],\n",
    "            'mean_delay':[arr_mean, dep_mean],\n",
    "           'median_delay': [arr_median, dep_median],\n",
    "           'airline': [arr_airling, dep_airling],\n",
    "           'top_months': [arr_months, dep_months]} \n",
    "    df = pd.DataFrame(data)\n",
    "    df.index = ['ARRIVING', 'DEPARTING']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    ">>> fp = os.path.join('data', 'to_from_san.csv')\n",
    ">>> dtypes = data_types()\n",
    ">>> flights = pd.read_csv(fp, dtype=dtypes)\n",
    ">>> out = basic_stats(flights)\n",
    ">>> print(out.index.tolist() == ['ARRIVING', 'DEPARTING'])\n",
    "# True\n",
    ">>> cols = ['count', 'mean_delay', 'median_delay', 'airline', 'top_months']\n",
    ">>> print(out.columns.tolist() == cols)\n",
    "# True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean_delay</th>\n",
       "      <th>median_delay</th>\n",
       "      <th>airline</th>\n",
       "      <th>top_months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ARRIVING</th>\n",
       "      <td>70207</td>\n",
       "      <td>3.676826</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>AA</td>\n",
       "      <td>[7, 8, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEPARTING</th>\n",
       "      <td>70207</td>\n",
       "      <td>3.328988</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>AA</td>\n",
       "      <td>[7, 8, 6]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count  mean_delay  median_delay airline top_months\n",
       "ARRIVING   70207    3.676826          -4.0      AA  [7, 8, 6]\n",
       "DEPARTING  70207    3.328988          -5.0      AA  [7, 8, 6]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'to_from_san.csv')\n",
    "dtypes = proj.data_types()\n",
    "flights = pd.read_csv(fp, dtype=dtypes)\n",
    "out = proj.basic_stats(flights)\n",
    "out.index.tolist() == ['ARRIVING', 'DEPARTING']\n",
    "#     True\n",
    "cols = ['count', 'mean_delay', 'median_delay', 'airline', 'top_months']\n",
    "out.columns.tolist() == cols\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding flight delays: Departures, Arrivals, and everything in-between\n",
    "\n",
    "**Step 4**\n",
    "\n",
    "Often `DEPARTURE_DELAY` is thought to be the main cause of a flight delay -- i.e., when the flight is late pushing off from the gate. \n",
    "\n",
    "However, there are other ways that flights can be late: waiting on the tarmac, headwinds, turbulence, circling a busy airport, and waiting for a gate after landing. First, we will analyze all the ways in which a flight can be delayed.\n",
    "\n",
    "* First, create a function `depart_arrive_stats` that takes in a dataframe like `flights` and calculates the following quantities in a series, indexed by `late1`, `late2`, `late3`:\n",
    "    - The proportion of flights from/to SAN that leave late, but arrive early or on-time (`late1`).\n",
    "    - The proportion of flights from/to SAN that leaves early, or on-time, but arrives late (`late2`).\n",
    "    - The proportion of flights from/to SAN that both left late and arrived late (`late3`).\n",
    "    \n",
    "* Second, create a function `depart_arrive_stats_by_month` that takes in a dataframe like `flights` and calculates the quantities above broken down by *month*. That is, the output is a dataframe, indexed by `MONTH`, with columns given by `late1`, `late2`, `late3`.\n",
    "\n",
    "*Remark:* Does this question reveal any data quality issues? Can you pinpoint when these issues occur?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depart_arrive_stats(flights):\n",
    "    \"\"\"\n",
    "    depart_arrive_stats takes in a dataframe like flights and calculates the\n",
    "    following quantities in a series (with the index in parentheses):\n",
    "    - The proportion of flights from/to SAN that\n",
    "      leave late, but arrive early or on-time (late1).\n",
    "    - The proportion of flights from/to SAN that\n",
    "      leaves early, or on-time, but arrives late (late2).\n",
    "    - The proportion of flights from/to SAN that\n",
    "      both left late and arrived late (late3).\n",
    "    \"\"\"\n",
    "    #late 1\n",
    "    late1 = ((flights['ARRIVAL_DELAY'] <= 0) & (flights['DEPARTURE_DELAY'] > 0)).mean()\n",
    "    #late 2\n",
    "    late2 = ((flights['DEPARTURE_DELAY'] <= 0) & (flights['ARRIVAL_DELAY'] > 0)).mean()\n",
    "    #late 3\n",
    "    late3 = ((flights['DEPARTURE_DELAY'] > 0) & (flights['ARRIVAL_DELAY'] > 0)).mean()\n",
    "    return pd.Series([late1, late2, late3], index=[\"late1\", \"late2\", \"late3\"])\n",
    "\n",
    "\n",
    "def depart_arrive_stats_by_month(flights):\n",
    "    \"\"\"\n",
    "    depart_arrive_stats_by_month takes in a dataframe like flights and\n",
    "    calculates the quantities in depart_arrive_stats, broken down by month\n",
    "    \"\"\"\n",
    "    \n",
    "    month = flights[['MONTH', 'DEPARTURE_DELAY', 'ARRIVAL_DELAY']].copy()\n",
    "    late1 = (month['ARRIVAL_DELAY'] <= 0) & (month['DEPARTURE_DELAY'] > 0)\n",
    "    late2 = (flights['DEPARTURE_DELAY'] <= 0) & (flights['ARRIVAL_DELAY'] > 0)\n",
    "    late3 = (flights['DEPARTURE_DELAY'] > 0) & (flights['ARRIVAL_DELAY'] > 0)\n",
    "    month['late1'] = late1\n",
    "    month['late2'] = late2\n",
    "    month['late3'] = late3\n",
    "    return month.groupby('MONTH')[['late1', 'late2', 'late3']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "late1    0.119853\n",
       "late2    0.089329\n",
       "late3    0.278804\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = depart_arrive_stats(flights)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>late1</th>\n",
       "      <th>late2</th>\n",
       "      <th>late3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MONTH</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.119063</td>\n",
       "      <td>0.095645</td>\n",
       "      <td>0.270501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.118087</td>\n",
       "      <td>0.096915</td>\n",
       "      <td>0.289925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.130521</td>\n",
       "      <td>0.089240</td>\n",
       "      <td>0.258309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.116475</td>\n",
       "      <td>0.095064</td>\n",
       "      <td>0.264326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.114136</td>\n",
       "      <td>0.083498</td>\n",
       "      <td>0.285151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.121138</td>\n",
       "      <td>0.088248</td>\n",
       "      <td>0.330968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.115371</td>\n",
       "      <td>0.095455</td>\n",
       "      <td>0.335799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.123828</td>\n",
       "      <td>0.086890</td>\n",
       "      <td>0.272450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.110409</td>\n",
       "      <td>0.087890</td>\n",
       "      <td>0.185905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.126393</td>\n",
       "      <td>0.081468</td>\n",
       "      <td>0.243735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.122793</td>\n",
       "      <td>0.082745</td>\n",
       "      <td>0.318700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          late1     late2     late3\n",
       "MONTH                              \n",
       "1      0.119063  0.095645  0.270501\n",
       "2      0.118087  0.096915  0.289925\n",
       "3      0.130521  0.089240  0.258309\n",
       "4      0.116475  0.095064  0.264326\n",
       "5      0.114136  0.083498  0.285151\n",
       "6      0.121138  0.088248  0.330968\n",
       "7      0.115371  0.095455  0.335799\n",
       "8      0.123828  0.086890  0.272450\n",
       "9      0.110409  0.087890  0.185905\n",
       "11     0.126393  0.081468  0.243735\n",
       "12     0.122793  0.082745  0.318700"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = depart_arrive_stats_by_month(flights)\n",
    "out.columns.tolist() == ['late1', 'late2', 'late3']\n",
    "#     True\n",
    "print(set(out.index) <= set(range(1, 13)))\n",
    "# #     True\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flight delays and day of the week\n",
    "\n",
    "**Step 5**\n",
    "\n",
    "Next, we'd like to understand the flight traffic to/from SAN by day of the week. Day of the week is specified by integers 1 through 7; verify which integer corresponds to which day.\n",
    "\n",
    "Next create two functions to understand both the amount of traffic and the average flight delay of flights for each airline by day-of-the week. We both want to understand *presence* each airline has as well as their *performance*.\n",
    "\n",
    "1. Create a function `cnts_by_airline_dow` that takes in a dataframe like `flights` and outputs a dataframe that answers the following question: Given any `AIRLINE` and `DAY_OF_WEEK`, how many flights were there (in 2015)?\n",
    "\n",
    "\n",
    "2. Create a function `mean_by_airline_dow` that takes in a dataframe like `flights` and outputs a dataframe that answers the following question: Given any `AIRLINE` and `DAY_OF_WEEK`, what is the average `ARRIVAL_DELAY` (in 2015)?\n",
    "\n",
    "Both dataframes should have a column for each distinct value of `AIRLINE` and a row for each `DAY_OF_WEEK`.\n",
    "\n",
    "The output has the *form* of the table below (not the entries themselves!)\n",
    "\n",
    "<img src=\"pivot.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnts_by_airline_dow(flights):\n",
    "    \"\"\"\n",
    "    mean_by_airline_dow takes in a dataframe like flights and outputs a\n",
    "    dataframe that answers the question:\n",
    "    Given any AIRLINE and DAY_OF_WEEK, how many flights were there (in 2015)?\n",
    "    \"\"\"\n",
    "    df = flights.pivot_table(\n",
    "        values  = \"DAY\",\n",
    "        index   = \"DAY_OF_WEEK\",\n",
    "        columns = \"AIRLINE\",\n",
    "        aggfunc = \"count\",\n",
    "        fill_value = 0\n",
    "    )\n",
    "    return df    \n",
    "\n",
    "\n",
    "def mean_by_airline_dow(flights):\n",
    "    \"\"\"\n",
    "    mean_by_airline_dow takes in a dataframe like flights and outputs a\n",
    "    dataframe that answers the question:\n",
    "    Given any AIRLINE and DAY_OF_WEEK, what is the average ARRIVAL_DELAY (in\n",
    "    2015)?\n",
    "    \"\"\"\n",
    "    df2 = flights.pivot_table(\n",
    "        values  = \"ARRIVAL_DELAY\",\n",
    "        index   = \"DAY_OF_WEEK\",\n",
    "        columns = \"AIRLINE\",\n",
    "        aggfunc = \"mean\",\n",
    "        fill_value = 0\n",
    "    )\n",
    "    return df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>AIRLINE</th>\n",
       "      <th>AA</th>\n",
       "      <th>AS</th>\n",
       "      <th>B6</th>\n",
       "      <th>DL</th>\n",
       "      <th>F9</th>\n",
       "      <th>HA</th>\n",
       "      <th>NK</th>\n",
       "      <th>OO</th>\n",
       "      <th>UA</th>\n",
       "      <th>US</th>\n",
       "      <th>VX</th>\n",
       "      <th>WN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1915</td>\n",
       "      <td>1564</td>\n",
       "      <td>384</td>\n",
       "      <td>1753</td>\n",
       "      <td>218</td>\n",
       "      <td>96</td>\n",
       "      <td>531</td>\n",
       "      <td>1859</td>\n",
       "      <td>2369</td>\n",
       "      <td>495</td>\n",
       "      <td>536</td>\n",
       "      <td>9238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1872</td>\n",
       "      <td>1345</td>\n",
       "      <td>359</td>\n",
       "      <td>1647</td>\n",
       "      <td>210</td>\n",
       "      <td>96</td>\n",
       "      <td>529</td>\n",
       "      <td>1829</td>\n",
       "      <td>2211</td>\n",
       "      <td>463</td>\n",
       "      <td>544</td>\n",
       "      <td>9300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1922</td>\n",
       "      <td>1428</td>\n",
       "      <td>359</td>\n",
       "      <td>1719</td>\n",
       "      <td>227</td>\n",
       "      <td>96</td>\n",
       "      <td>530</td>\n",
       "      <td>1814</td>\n",
       "      <td>2293</td>\n",
       "      <td>472</td>\n",
       "      <td>542</td>\n",
       "      <td>9328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1888</td>\n",
       "      <td>1551</td>\n",
       "      <td>380</td>\n",
       "      <td>1729</td>\n",
       "      <td>220</td>\n",
       "      <td>96</td>\n",
       "      <td>531</td>\n",
       "      <td>1835</td>\n",
       "      <td>2328</td>\n",
       "      <td>510</td>\n",
       "      <td>531</td>\n",
       "      <td>9108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1859</td>\n",
       "      <td>1449</td>\n",
       "      <td>376</td>\n",
       "      <td>1701</td>\n",
       "      <td>208</td>\n",
       "      <td>94</td>\n",
       "      <td>518</td>\n",
       "      <td>1813</td>\n",
       "      <td>2279</td>\n",
       "      <td>505</td>\n",
       "      <td>523</td>\n",
       "      <td>9006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1755</td>\n",
       "      <td>1476</td>\n",
       "      <td>270</td>\n",
       "      <td>1433</td>\n",
       "      <td>195</td>\n",
       "      <td>94</td>\n",
       "      <td>518</td>\n",
       "      <td>1837</td>\n",
       "      <td>1743</td>\n",
       "      <td>496</td>\n",
       "      <td>365</td>\n",
       "      <td>7201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1886</td>\n",
       "      <td>1465</td>\n",
       "      <td>387</td>\n",
       "      <td>1726</td>\n",
       "      <td>214</td>\n",
       "      <td>96</td>\n",
       "      <td>532</td>\n",
       "      <td>1889</td>\n",
       "      <td>2172</td>\n",
       "      <td>503</td>\n",
       "      <td>443</td>\n",
       "      <td>8587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "AIRLINE        AA    AS   B6    DL   F9  HA   NK    OO    UA   US   VX    WN\n",
       "DAY_OF_WEEK                                                                 \n",
       "1            1915  1564  384  1753  218  96  531  1859  2369  495  536  9238\n",
       "2            1872  1345  359  1647  210  96  529  1829  2211  463  544  9300\n",
       "3            1922  1428  359  1719  227  96  530  1814  2293  472  542  9328\n",
       "4            1888  1551  380  1729  220  96  531  1835  2328  510  531  9108\n",
       "5            1859  1449  376  1701  208  94  518  1813  2279  505  523  9006\n",
       "6            1755  1476  270  1433  195  94  518  1837  1743  496  365  7201\n",
       "7            1886  1465  387  1726  214  96  532  1889  2172  503  443  8587"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = cnts_by_airline_dow(flights)\n",
    "print(set(out.columns) == set(flights['AIRLINE'].unique()))\n",
    "#     True\n",
    "print(set(out.index) == set(flights['DAY_OF_WEEK'].unique()))\n",
    "#     True\n",
    "print((out >= 0).all().all())\n",
    "#     True\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>AIRLINE</th>\n",
       "      <th>AA</th>\n",
       "      <th>AS</th>\n",
       "      <th>B6</th>\n",
       "      <th>DL</th>\n",
       "      <th>F9</th>\n",
       "      <th>HA</th>\n",
       "      <th>NK</th>\n",
       "      <th>OO</th>\n",
       "      <th>UA</th>\n",
       "      <th>US</th>\n",
       "      <th>VX</th>\n",
       "      <th>WN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.245981</td>\n",
       "      <td>-2.652286</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>-3.096904</td>\n",
       "      <td>3.233945</td>\n",
       "      <td>5.842105</td>\n",
       "      <td>9.222656</td>\n",
       "      <td>7.405257</td>\n",
       "      <td>3.081280</td>\n",
       "      <td>1.764344</td>\n",
       "      <td>12.804878</td>\n",
       "      <td>6.355997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.791037</td>\n",
       "      <td>-4.535474</td>\n",
       "      <td>4.507123</td>\n",
       "      <td>-2.988408</td>\n",
       "      <td>4.975728</td>\n",
       "      <td>7.385417</td>\n",
       "      <td>10.669903</td>\n",
       "      <td>5.109574</td>\n",
       "      <td>5.617431</td>\n",
       "      <td>1.354626</td>\n",
       "      <td>4.645522</td>\n",
       "      <td>5.394194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.811808</td>\n",
       "      <td>-4.030899</td>\n",
       "      <td>2.735043</td>\n",
       "      <td>-2.437098</td>\n",
       "      <td>5.634361</td>\n",
       "      <td>16.833333</td>\n",
       "      <td>6.304264</td>\n",
       "      <td>5.566741</td>\n",
       "      <td>3.686344</td>\n",
       "      <td>-2.145299</td>\n",
       "      <td>0.631970</td>\n",
       "      <td>3.556762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.076552</td>\n",
       "      <td>-2.180995</td>\n",
       "      <td>3.152406</td>\n",
       "      <td>-2.339721</td>\n",
       "      <td>4.531818</td>\n",
       "      <td>7.552083</td>\n",
       "      <td>7.931298</td>\n",
       "      <td>7.971901</td>\n",
       "      <td>4.957124</td>\n",
       "      <td>1.198397</td>\n",
       "      <td>8.277040</td>\n",
       "      <td>6.582300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.235679</td>\n",
       "      <td>-1.040887</td>\n",
       "      <td>3.329759</td>\n",
       "      <td>-5.699528</td>\n",
       "      <td>4.830918</td>\n",
       "      <td>8.021505</td>\n",
       "      <td>7.242718</td>\n",
       "      <td>5.920156</td>\n",
       "      <td>1.756997</td>\n",
       "      <td>3.017928</td>\n",
       "      <td>9.325536</td>\n",
       "      <td>7.961504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.427912</td>\n",
       "      <td>-3.283673</td>\n",
       "      <td>-1.854478</td>\n",
       "      <td>-3.608726</td>\n",
       "      <td>0.119171</td>\n",
       "      <td>7.159574</td>\n",
       "      <td>6.943026</td>\n",
       "      <td>3.746961</td>\n",
       "      <td>-1.338924</td>\n",
       "      <td>-2.227926</td>\n",
       "      <td>0.101370</td>\n",
       "      <td>1.684625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.611924</td>\n",
       "      <td>-2.318213</td>\n",
       "      <td>2.422043</td>\n",
       "      <td>-4.857392</td>\n",
       "      <td>6.112150</td>\n",
       "      <td>5.229167</td>\n",
       "      <td>8.754753</td>\n",
       "      <td>8.570806</td>\n",
       "      <td>-0.190121</td>\n",
       "      <td>2.257545</td>\n",
       "      <td>12.594533</td>\n",
       "      <td>6.867543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "AIRLINE            AA        AS        B6        DL        F9         HA  \\\n",
       "DAY_OF_WEEK                                                                \n",
       "1            2.245981 -2.652286  0.928571 -3.096904  3.233945   5.842105   \n",
       "2            0.791037 -4.535474  4.507123 -2.988408  4.975728   7.385417   \n",
       "3            1.811808 -4.030899  2.735043 -2.437098  5.634361  16.833333   \n",
       "4            4.076552 -2.180995  3.152406 -2.339721  4.531818   7.552083   \n",
       "5            1.235679 -1.040887  3.329759 -5.699528  4.830918   8.021505   \n",
       "6           -0.427912 -3.283673 -1.854478 -3.608726  0.119171   7.159574   \n",
       "7            1.611924 -2.318213  2.422043 -4.857392  6.112150   5.229167   \n",
       "\n",
       "AIRLINE             NK        OO        UA        US         VX        WN  \n",
       "DAY_OF_WEEK                                                                \n",
       "1             9.222656  7.405257  3.081280  1.764344  12.804878  6.355997  \n",
       "2            10.669903  5.109574  5.617431  1.354626   4.645522  5.394194  \n",
       "3             6.304264  5.566741  3.686344 -2.145299   0.631970  3.556762  \n",
       "4             7.931298  7.971901  4.957124  1.198397   8.277040  6.582300  \n",
       "5             7.242718  5.920156  1.756997  3.017928   9.325536  7.961504  \n",
       "6             6.943026  3.746961 -1.338924 -2.227926   0.101370  1.684625  \n",
       "7             8.754753  8.570806 -0.190121  2.257545  12.594533  6.867543  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2\n",
    "out = proj.mean_by_airline_dow(flights)\n",
    "print(set(out.columns) == set(flights['AIRLINE'].unique()))\n",
    "#     True\n",
    "print(set(out.index) == set(flights['DAY_OF_WEEK'].unique()))\n",
    "#     True\n",
    "out#5.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding null values in the flights data\n",
    "\n",
    "**Step 6 (Missing by Design)**\n",
    "\n",
    "Now we would like to understand how data is missing in the flights data. First, compute the proportion of each column of `flights` which are non-null. \n",
    "\n",
    "Recall that a column is *missing by design* if you can determine when the entry of a column is missing based solely on other data in the same row. That is\n",
    "* there is *no randomness* in determining when an entry is missing.\n",
    "* you can describe when the column is missing a value with a logical (not random) condition.\n",
    "* you can express which rows will have missing values in terms of logical statements about the *other* columns in the same row.\n",
    "\n",
    "For this question, verify the following columns are *missing by design*:\n",
    "* The column `ARRIVAL_DELAY` is *missing by design*. Create a function `predict_null_arrival_delay` that doesn't depend on the values of `ARRIVAL_DELAY`, that:\n",
    "    - Takes in a row of the flights data (that is, a Series)\n",
    "    - Returns `True` if and only if the `ARRIVAL_DELAY` is null; otherwise it returns `False`.\n",
    "    - Since the function doesn't depend on `ARRIVAL_DELAY`, it should work on a row even if the `ARRIVAL_DELAY` index is dropped.\n",
    "    \n",
    "\n",
    "\n",
    "* The column `AIRLINE_DELAY` is *missing by design*. As above, create a function `predict_null_airline_delay` that doesn't depend on the values of `AIRLINE_DELAY`, that:\n",
    "    - Takes in a row of the flights data (that is, a Series)\n",
    "    - Returns `True` if and only if the `AIRLINE_DELAY` is null; otherwise it returns `False`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_null_arrival_delay(row):\n",
    "    \"\"\"\n",
    "    predict_null takes in a row of the flights data (that is, a Series) and\n",
    "    returns True if the ARRIVAL_DELAY is null and otherwise False.\n",
    "\n",
    "    :param row: a Series that represents a row of `flights`\n",
    "    :returns: a boolean representing when `ARRIVAL_DELAY` is null.\n",
    "    \"\"\"\n",
    "    return pd.isnull(row['ELAPSED_TIME'])\n",
    "\n",
    "\n",
    "def predict_null_airline_delay(row):\n",
    "    \"\"\"\n",
    "    predict_null takes in a row of the flights data (that is, a Series) and\n",
    "    returns True if the AIRLINE_DELAY is null and otherwise False. Since the\n",
    "    function doesn't depend on AIRLINE_DELAY, it should work a row even if that\n",
    "    index is dropped.\n",
    "\n",
    "    :param row: a Series that represents a row of `flights`\n",
    "    :returns: a boolean representing when `AIRLINE_DELAY` is null.\n",
    "    \"\"\"\n",
    "\n",
    "    return pd.isnull(row['AIR_SYSTEM_DELAY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     False\n",
       "1     False\n",
       "2     False\n",
       "3     False\n",
       "4     False\n",
       "5     False\n",
       "6     False\n",
       "7     False\n",
       "8     False\n",
       "9     False\n",
       "10    False\n",
       "11    False\n",
       "12    False\n",
       "13    False\n",
       "14    False\n",
       "15    False\n",
       "16    False\n",
       "17    False\n",
       "18    False\n",
       "19    False\n",
       "20    False\n",
       "21    False\n",
       "22    False\n",
       "23    False\n",
       "24    False\n",
       "25    False\n",
       "26    False\n",
       "27    False\n",
       "28    False\n",
       "29    False\n",
       "      ...  \n",
       "70    False\n",
       "71    False\n",
       "72    False\n",
       "73    False\n",
       "74    False\n",
       "75    False\n",
       "76    False\n",
       "77    False\n",
       "78    False\n",
       "79    False\n",
       "80    False\n",
       "81    False\n",
       "82    False\n",
       "83     True\n",
       "84    False\n",
       "85    False\n",
       "86    False\n",
       "87    False\n",
       "88    False\n",
       "89    False\n",
       "90    False\n",
       "91    False\n",
       "92    False\n",
       "93    False\n",
       "94    False\n",
       "95    False\n",
       "96    False\n",
       "97    False\n",
       "98    False\n",
       "99    False\n",
       "Length: 100, dtype: bool"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> fp = os.path.join('data', 'to_from_san.csv')\n",
    ">>> flights = pd.read_csv(fp, nrows=100)\n",
    ">>> out = flights.drop('ARRIVAL_DELAY', axis=1).apply(predict_null_arrival_delay, axis=1)\n",
    ">>> print(set(out.unique()) - set([True, False]) == set())\n",
    "# True\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      True\n",
       "1      True\n",
       "2      True\n",
       "3      True\n",
       "4      True\n",
       "5      True\n",
       "6      True\n",
       "7      True\n",
       "8      True\n",
       "9      True\n",
       "10     True\n",
       "11     True\n",
       "12     True\n",
       "13     True\n",
       "14     True\n",
       "15     True\n",
       "16     True\n",
       "17     True\n",
       "18     True\n",
       "19    False\n",
       "20     True\n",
       "21    False\n",
       "22     True\n",
       "23     True\n",
       "24     True\n",
       "25     True\n",
       "26     True\n",
       "27    False\n",
       "28     True\n",
       "29     True\n",
       "      ...  \n",
       "70     True\n",
       "71     True\n",
       "72     True\n",
       "73    False\n",
       "74     True\n",
       "75    False\n",
       "76     True\n",
       "77     True\n",
       "78     True\n",
       "79     True\n",
       "80     True\n",
       "81     True\n",
       "82     True\n",
       "83     True\n",
       "84     True\n",
       "85     True\n",
       "86     True\n",
       "87     True\n",
       "88     True\n",
       "89    False\n",
       "90     True\n",
       "91     True\n",
       "92     True\n",
       "93     True\n",
       "94     True\n",
       "95     True\n",
       "96     True\n",
       "97     True\n",
       "98     True\n",
       "99    False\n",
       "Length: 100, dtype: bool"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> fp = os.path.join('data', 'to_from_san.csv')\n",
    ">>> flights = pd.read_csv(fp, nrows=100)\n",
    ">>> out = flights.drop('AIRLINE_DELAY', axis=1).apply(predict_null_airline_delay, axis=1)\n",
    ">>> print(set(out.unique()) - set([True, False]) == set())\n",
    "# True\n",
    "out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 7 (Missingness Types)**\n",
    "\n",
    "Now we'd like to determine missingness of the column `DEPARTURE_DELAY`. In particular, we'd like to perform a permutation test to determine the missingness of `DEPARTURE_DELAY` dependent on the column `AIRLINE`.\n",
    "\n",
    "* Create a function `perm4missing`:\n",
    "    - that takes in `flights`, a column `col`, and a number `N` and \n",
    "    - returns the p-value of the test (using `N` simulations) that determines if `DEPARTURE_DELAY` is MAR dependent on `col`. That is `perm4missing(flights, 'AIRLINE', N)` should return the p-value for the test above.\n",
    "   \n",
    "    \n",
    "* Use the function above to determine the columns `col` for which \"`DEPARTURE_DELAY` is MAR dependent on `col`\" using a significance level of 0.01. Only consider the categorical columns `YEAR`,`DAY_OF_WEEK`, `AIRLINE`,`DIVERTED`, `CANCELLATION_REASON`. Return your answer in a (hard-coded) list returned by a function called `dependent_cols`.\n",
    "\n",
    "* Create a function `missing_types` of zero variables, which:\n",
    "    - Returns a Series, indexed by the following columns of `flights`: `CANCELLED`, `CANCELLATION_REASON`, `TAIL_NUMBER`, `ARRIVAL_TIME`.\n",
    "    - The values should contain the most-likely missingness type of each column. \n",
    "    - The values of this Series should be `MD, MCAR, MAR, MNAR, NaN` (use `NaN` if there are no missing values). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perm4missing(flights, col, N):\n",
    "    \"\"\"\n",
    "    perm4missing takes in flights, a column col, and a number N and returns the\n",
    "    p-value of the test (using N simulations) that determines if\n",
    "    DEPARTURE_DELAY is MAR dependent on col.\n",
    "    \"\"\"\n",
    "\n",
    "    flights_dep = flights.assign(isnull = flights['DEPARTURE_DELAY'].isnull())[['isnull', col]]\n",
    "    distr = flights_dep.pivot_table(columns='isnull', index=col, aggfunc='size', fill_value=0).apply(lambda x: x / x.sum())\n",
    "    observed_tvd = np.sum(np.abs(distr.diff(axis=1).iloc[:,-1])) / 2\n",
    "    tvds = []\n",
    "    for _ in range(N):\n",
    "        airline_shuffled = (\n",
    "            flights_dep[col]\n",
    "            .sample(replace=False, frac=1)\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "        flights_dep_shuffled = flights_dep.assign(airline_shuffled = airline_shuffled)\n",
    "        shuffled_distr = (flights_dep_shuffled\n",
    "                          .pivot_table(columns='isnull', index='airline_shuffled', aggfunc='size', fill_value=0)\n",
    "                          .apply(lambda x: x / x.sum()))\n",
    "        tvd = np.sum(np.abs(shuffled_distr.diff(axis=1).iloc[:,-1])) / 2\n",
    "        tvds.append(tvd)\n",
    "    p_val = np.count_nonzero(np.array(tvds) > observed_tvd) / N\n",
    "\n",
    "    return p_val\n",
    "    \n",
    "     \n",
    "\n",
    "\n",
    "def dependent_cols():\n",
    "    \"\"\"\n",
    "    dependent_cols gives a list of columns on which DEPARTURE_DELAY is MAR\n",
    "    dependent on.\n",
    "\n",
    "    :Example:\n",
    "    >>> out = dependent_cols()\n",
    "    >>> isinstance(out, list)\n",
    "    True\n",
    "    >>> cols = 'YEAR DAY_OF_WEEK AIRLINE DIVERTED CANCELLATION_REASON'.split()\n",
    "    >>> set(out) <= set(cols)\n",
    "    True\n",
    "    \"\"\"\n",
    "    return ['YEAR','DAY_OF_WEEK']\n",
    "\n",
    "\n",
    "def missing_types():\n",
    "    \"\"\"\n",
    "    missing_types returns a Series\n",
    "    - indexed by the following columns of flights:\n",
    "    CANCELLED, CANCELLATION_REASON, TAIL_NUMBER, ARRIVAL_TIME.\n",
    "    - The values contain the most-likely missingness type of each column.\n",
    "    - The unique values of this Series should be MD, MCAR, MAR, MNAR, NaN.\n",
    "\n",
    "    :param:\n",
    "    :returns: A series with index and values as described above.\n",
    "    \"\"\"\n",
    "    return pd.Series([np.nan, 'MAR', 'MCAR', 'MD'], index=['CANCELLED', 'CANCELLATION_REASON', 'TAIL_NUMBER', 'ARRIVAL_TIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.36"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    ">>> fp = os.path.join('data', 'to_from_san.csv')\n",
    ">>> flights = pd.read_csv(fp, nrows=100)\n",
    ">>> out = perm4missing(flights, 'AIRLINE', 100)\n",
    ">>> print(0 <= out <= 1)\n",
    "# True\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CANCELLED               NaN\n",
       "CANCELLATION_REASON     MAR\n",
       "TAIL_NUMBER            MCAR\n",
       "ARRIVAL_TIME             MD\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    ">>> out = missing_types()\n",
    ">>> print(isinstance(out, pd.Series))\n",
    "# True\n",
    ">>> print(set(out.unique()) - set(['MD', 'MCAR', 'MAR', 'MNAR', np.NaN]) == set())\n",
    "# True\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpson's Paradox: JetBlue vs Southwest\n",
    "\n",
    "The remainder of the questions investigates the presence of Simpson's paradox in the flights dataset. \n",
    "\n",
    "The csv file `southwest_vs_jetblue.csv` contains all Southwest and JetBlue flights in 2015.\n",
    "\n",
    "In this dataset, we are going to verify the following occurrences of Simpson's Paradox: For a given set of airports,\n",
    "* The average departure delay of Southwest is greater than (or less than) the average departure delay of JetBlue.\n",
    "* Airport by airport, the average departure delay of Southwest is *less* than (or greater than) the average departure delay of JetBlue.\n",
    "\n",
    "That is, the inequalities of the average flight delays between the two airlines are reversed when viewed at the level of each airport. In fact this reversal holds for *every* airport being considered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 8**\n",
    "\n",
    "Filter the dataset `jb_sw` to flights *originating* from the following 10 airports: ABQ, BDL, BUR, DCA, MSY, PBI, PHX, RNO, SJC, SLC.\n",
    "\n",
    "Illustrate Simpson's paradox with this table:\n",
    "* Calculate the proportion of each airline's flights that are delayed (at each of the 10 airports):\n",
    "    - Create a function `prop_delayed_by_airline` that takes in a dataframe like `jb_sw` and returns a DataFrame indexed by airline that contains the proportion of each airline's flights that are delayed.\n",
    "* Calculate these proportions across all airports in the dataset (at each of the 10 airports):\n",
    "    - Create a function `prop_delayed_by_airline_airport` that takes in a dataframe like `jb_sw` and returns a DataFrame, with columns given by airports, indexed by airline, that contains the proportion of each airline's flights that are delayed at each airport.\n",
    "\n",
    "*Remark:* For the purpose of this question, a canceled flight is **not** delayed.\n",
    "\n",
    "Verify that Simpson's paradox is present in this output! \n",
    "\n",
    "Can you explain *why* Simpson's paradox is occurring? (Hint: where are these airports located? Which have the most flights?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prop_delayed_by_airline(jb_sw):\n",
    "    \"\"\"\n",
    "    prop_delayed_by_airline takes in a dataframe like jb_sw and returns a\n",
    "    DataFrame indexed by airline that contains the proportion of each airline's\n",
    "    flights that are delayed.\n",
    "\n",
    "    :param jb_sw: a dataframe similar to jb_sw\n",
    "    :returns: a dataframe as above\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    # Filter\n",
    "    airports = ['ABQ', 'BDL', 'BUR', 'DCA', 'MSY', 'PBI', 'PHX', 'RNO', 'SJC', 'SLC']\n",
    "    fil = jb_sw['ORIGIN_AIRPORT'].apply(lambda x : x in airports)\n",
    "    filtered_jb_sw = jb_sw.loc[fil]\n",
    "\n",
    "    # Calculate the proportion\n",
    "    delayed = (filtered_jb_sw['DEPARTURE_DELAY'] > 0) & (filtered_jb_sw['CANCELLED'] == 0)\n",
    "    filtered_jb_sw = filtered_jb_sw.assign(delayed = delayed)\n",
    "\n",
    "    return filtered_jb_sw[['AIRLINE', 'delayed']].groupby('AIRLINE').mean()\n",
    "\n",
    "\n",
    "def prop_delayed_by_airline_airport(jb_sw):\n",
    "    \"\"\"\n",
    "    prop_delayed_by_airline_airport that takes in a dataframe like jb_sw and\n",
    "    returns a DataFrame, with columns given by airports, indexed by airline,\n",
    "    that contains the proportion of each airline's flights that are delayed at\n",
    "    each airport.\n",
    "\n",
    "    :param jb_sw: a dataframe similar to jb_sw\n",
    "    :returns: a dataframe as above.\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    # Filter\n",
    "    airports = ['ABQ', 'BDL', 'BUR', 'DCA', 'MSY', 'PBI', 'PHX', 'RNO', 'SJC', 'SLC']\n",
    "    fil = jb_sw['ORIGIN_AIRPORT'].apply(lambda x : x in airports)\n",
    "    filtered_jb_sw = jb_sw.loc[fil]\n",
    "\n",
    "    # Calculate the proportion of each airport\n",
    "    delayed = (filtered_jb_sw['DEPARTURE_DELAY'] > 0) & (filtered_jb_sw['CANCELLED'] == 0)\n",
    "    pivot = filtered_jb_sw.pivot_table(\n",
    "    index = 'AIRLINE',\n",
    "    columns = 'ORIGIN_AIRPORT',\n",
    "    values = 'YEAR',\n",
    "    aggfunc = 'count'\n",
    "    )\n",
    "    #changed\n",
    "    pivot = pivot.div(pivot.sum(1), 0)\n",
    "    \n",
    "\n",
    "    return pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delayed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIRLINE</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B6</th>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WN</th>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          delayed\n",
       "AIRLINE          \n",
       "B6       0.285714\n",
       "WN       0.666667"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    ">>> fp = os.path.join('data', 'jetblue_or_sw.csv')\n",
    ">>> jb_sw = pd.read_csv(fp, nrows=100)\n",
    ">>> out = prop_delayed_by_airline(jb_sw)\n",
    ">>> print(isinstance(out, pd.DataFrame))\n",
    "# True\n",
    ">>> print((out >= 0).all().all() and (out <= 1).all().all())\n",
    "# True\n",
    ">>> print(len(out.columns) == 1)\n",
    "# True\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ORIGIN_AIRPORT</th>\n",
       "      <th>ABQ</th>\n",
       "      <th>BDL</th>\n",
       "      <th>DCA</th>\n",
       "      <th>MSY</th>\n",
       "      <th>PBI</th>\n",
       "      <th>PHX</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIRLINE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WN</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ORIGIN_AIRPORT       ABQ       BDL       DCA       MSY       PBI       PHX\n",
       "AIRLINE                                                                   \n",
       "B6                   NaN  0.142857  0.285714  0.142857  0.428571       NaN\n",
       "WN              0.333333       NaN       NaN       NaN       NaN  0.666667"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> fp = os.path.join('data', 'jetblue_or_sw.csv')\n",
    ">>> jb_sw = pd.read_csv(fp, nrows=100)\n",
    ">>> out = prop_delayed_by_airline_airport(jb_sw)\n",
    ">>> print(isinstance(out, pd.DataFrame))\n",
    "# True\n",
    ">>> print(((out >= 0) | (out <= 1) | (out.isnull())).all().all())\n",
    "# True\n",
    ">>> print(len(out.columns) == 6)\n",
    "# True\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in these two tables, the result of delay reversed! In general, WN has more delay than B6. However, B6 has more delay than WN in airports like BDL, DCA, MSY..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 9**\n",
    "\n",
    "Your work above illustrates Simpson's paradox on the specific dataset of flights originating from 10 specific airports. However, this still requires you to look at two dataframe to see if the paradox is present. Now, you will create a function that verifies Simpson's paradox in general. You will do this by writing code to compare the two dataframes, instead of inspecting them manually.\n",
    "\n",
    "Create a function `verify_simpson` that returns a boolean output regarding if the paradox is present.\n",
    "```\n",
    "verify_simpson(df, group1, group2, occur)\n",
    "```\n",
    "- df is a dataframe (e.g. jb_sw),\n",
    "- group1 is the first group being aggregated against (e.g. `AIRLINE`),\n",
    "- group2 is the second group being aggregated against (e.g. `ORIGIN_AIRPORT`),\n",
    "- occur is a column with values {0, 1}, denoting if an event occurred for that individual.\n",
    "  (e.g. \"1 if flight was delayed\" and \"0 if flight was not delayed\")\n",
    "\n",
    "`verify_simpson` should return `True` only if there is a reversal for *every* value of `group2` (e.g. for every airport).\n",
    "\n",
    "Example:\n",
    "\n",
    "Consider the following dataframe `df` with columns `treatment`, `stone_size`, and `success`:\n",
    "\n",
    "|treatment|stone_size|success|\n",
    "|---|---|---|\n",
    "|A|small|1|\n",
    "|B|small|1|\n",
    "|...|...|...|\n",
    "|A|large|0|\n",
    "|B|small|0|\n",
    "|B|small|1|\n",
    "\n",
    "`df` corresponds to the following diagram:\n",
    "<img src=\"https://miro.medium.com/max/996/1*IfVjfdGD7RPwLDC6WzT9Uw.png\" style=\"width: 300px\"/>\n",
    "\n",
    "Here, `verify_simpson(df, 'treatment', 'stone_size', 'success')` should return `True`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_simpson(df, group1, group2, occur):\n",
    "    \"\"\"\n",
    "    verify_simpson verifies whether a dataset displays Simpson's Paradox.\n",
    "\n",
    "    :param df: a dataframe\n",
    "    :param group1: the first group being aggregated\n",
    "    :param group2: the second group being aggregated\n",
    "    :param occur: a column of df with values {0,1}, denoting\n",
    "    if an event occurred.\n",
    "    :returns: a boolean. True if simpson's paradox is present,\n",
    "    otherwise False.\n",
    "    \"\"\"\n",
    "\n",
    "    aggre = df.pivot_table(\n",
    "        values = [occur],\n",
    "        index = group1,\n",
    "        columns = group2,\n",
    "        aggfunc = 'mean'\n",
    "    )\n",
    "    origin = df.pivot_table(\n",
    "        columns = group2,\n",
    "        values = [occur],\n",
    "        aggfunc = 'mean'\n",
    "    )\n",
    "    aggre = aggre.fillna(0)\n",
    "    origin = origin.fillna(0)\n",
    "    original_value = (origin.diff().iloc[-1] < 0).all()\n",
    "    aggre_value = (aggre.diff().iloc[-1] < 0)\n",
    "    if aggre_value.sum() == aggre_value.shape[0] and original_value == False:\n",
    "        return True\n",
    "    elif original_value == True and aggre_value.sum() == 0:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    ">>> df = pd.DataFrame([[4,2,1], [1,2,0], [1,4,0], [4,4,1]], columns=[1,2,3])\n",
    ">>> print(verify_simpson(df, 1, 2, 3) in [True, False])\n",
    "# True\n",
    ">>> print(verify_simpson(df, 1, 2, 3))\n",
    "# False"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
