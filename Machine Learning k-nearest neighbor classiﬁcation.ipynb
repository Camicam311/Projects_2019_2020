{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    Task: \n",
    "We look at the task of classifying images of digits using k-nearest neighbor classiﬁcation. Files pa1train.txt, pa1validate.txt and pa1test.txt contain the training, validation and test data sets respectively. The images have already converted into vectors of pixel colors. The data ﬁles are in ASCII text format, and each line of the ﬁles contains a feature vector of size 784, followed by its label. The coordinates of the feature vector are separated by spaces.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary:\n",
    "### Part 1 without Projections\n",
    "| k | Train Errors | Validation Errors |\n",
    "| --- | --- | --- |\n",
    "| 1 | 0.0 | 0.082 |\n",
    "| 5 | 0.0565 | 0.095 |\n",
    "| 9 | 0.0685 | 0.103 |\n",
    "| 15 | 0.0925 | 0.108 |\n",
    "\n",
    "* Since $k=1$ performs the best on validation, I calculated the test error for k = 1, and it is $0.094$\n",
    "\n",
    "### Part 2 with Projections\n",
    "| k | Train Errors | Validation Errors |\n",
    "| --- | --- | --- |\n",
    "| 1 | 0.0 | 0.32 |\n",
    "| 5 | 0.1945 | 0.299 |\n",
    "| 9 | 0.2305 | 0.302 |\n",
    "| 15 | 0.257 | 0.289 |\n",
    "\n",
    "* Since $k=15$ performs the best on validation, I calculated the test error for k = 15, and it is $0.296$\n",
    "\n",
    "### How is the classiﬁcation accuracy aﬀected by projection?\n",
    "* The classiﬁcation accuracy with projection $went down$, because the number of x variables went down from 784 to 20. \n",
    "\n",
    "### How does the running time change on projected data?\n",
    "| Runtime | Train Errors (k = 1, 3, 5, 9, 15) | Validation Errors (k = 1, 5, 9, 15) | Test Error (k = 1 or 15)|\n",
    "| --- | --- | --- | --- |\n",
    "| without projection | 304.971 | 133.117 | 30.797|\n",
    "| with projection | 282.221 | 115.279 |28.491 |\n",
    "\n",
    "* The running time $decreases$ on projected data, because there are less columns put into the calculation of Euclidean distance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "##  Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from scipy.spatial import distance\n",
    "from scipy import stats\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train=np.loadtxt(\"pa1train.txt\")\n",
    "test=np.loadtxt(\"pa1test.txt\")\n",
    "validate=np.loadtxt(\"pa1validate.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Euclidean Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eu(a, b):\n",
    "    return distance.euclidean(a[:-1], b[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Function for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(data, data_, index, k):\n",
    "    len = data.shape[0]\n",
    "    dist = []\n",
    "    for i in range(len):\n",
    "        # Add the distance and the index of the example to an ordered collection\n",
    "        eu_d = eu(data_[index], data[i])\n",
    "        dist.append((eu_d, i))\n",
    "    #Sort the ordered collection of distances and indices from smallest to largest (in ascending order) by the distances\n",
    "    dist = sorted(dist)\n",
    "    # Pick the first K entries from the sorted collection\n",
    "    preds = dist[:k]\n",
    "    # Get the labels of the selected K entries\n",
    "    labels = [data[i[1]][-1] for i in preds]\n",
    "    # get the mode of the K labels\n",
    "    pred = stats.mode(labels)\n",
    "    # return true: if the predicted label is the same as the real lable, false: otherwise\n",
    "    return data_[index][-1] == pred[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Training Errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Training Error when k is equal to 1 is 0.0\n",
      "The Training Error when k is equal to 3 is 0.04349999999999998\n",
      "The Training Error when k is equal to 5 is 0.056499999999999995\n",
      "The Training Error when k is equal to 9 is 0.0685\n",
      "The Training Error when k is equal to 15 is 0.09250000000000003\n",
      "304.97118067741394\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "len = train.shape[0]\n",
    "ks = [1, 3, 5, 9, 15]\n",
    "for k in ks:\n",
    "    correct = []\n",
    "    for i in range(len):\n",
    "        correct.append(knn(train, train, i, k))\n",
    "    print('The Training Error when k is equal to ' + str(k) + ' is ' + str(1 - np.mean(correct)))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Validation Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Validation Error when k is equal to 1 is 0.08199999999999996\n",
      "The Validation Error when k is equal to 5 is 0.09499999999999997\n",
      "The Validation Error when k is equal to 9 is 0.10399999999999998\n",
      "The Validation Error when k is equal to 15 is 0.10799999999999998\n",
      "133.11728882789612\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "len = validate.shape[0]\n",
    "ks = [1, 5, 9, 15]\n",
    "for k in ks:\n",
    "    correct = []\n",
    "    for i in range(len):\n",
    "        correct.append(knn(train, validate, i, k))\n",
    "    print('The Validation Error when k is equal to ' + str(k) + ' is ' + str(1 - np.mean(correct)))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, of all of these classiﬁers, k = 1 performs the best on validation data, so I'm going to use k=1 to get the Test Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Test Error when k = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Test Error when k is equal to 1 is 0.09399999999999997\n",
      "30.797391891479492\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "len = test.shape[0]\n",
    "correct = []\n",
    "for i in range(len):\n",
    "    correct.append(knn(train, test, i, 1))\n",
    "print('The Test Error when k is equal to 1 is ' + str(1 - np.mean(correct)))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 summary\n",
    "| k | Train Errors | Validation Errors |\n",
    "| --- | --- | --- |\n",
    "| 1 | 0.0 | 0.082 |\n",
    "| 5 | 0.0565 | 0.095 |\n",
    "| 9 | 0.0685 | 0.103 |\n",
    "| 15 | 0.0925 | 0.108 |\n",
    "\n",
    "* Since k=1 performs the best on validation, I calculated the test error for k = 1, and it is 0.094"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "we will look at how using a projection as a pre-processing step aﬀects the accuracy and running-time of nearest neighbor classiﬁcation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Projection Data\n",
    "\n",
    "The ﬁle projection.txt represents a projection matrix P with 784 rows and 20 columns. Each column is a 784-dimensional unit vector, and the columns are orthogonal to each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.015626  , -0.019702  , -0.005087  , ..., -0.019012  ,\n",
       "        -0.053294  , -0.059311  ],\n",
       "       [-0.043534  ,  0.038514  ,  0.061698  , ...,  0.03185   ,\n",
       "         0.0024749 ,  0.00052616],\n",
       "       [-0.016051  , -0.016189  ,  0.030413  , ..., -0.0085923 ,\n",
       "         0.036698  ,  0.0069459 ],\n",
       "       ...,\n",
       "       [ 0.0084749 ,  0.017197  , -0.063448  , ...,  0.065384  ,\n",
       "        -0.0032644 ,  0.026077  ],\n",
       "       [-0.025274  ,  0.0051254 , -0.023191  , ...,  0.069659  ,\n",
       "        -0.047332  , -0.0442    ],\n",
       "       [-0.023108  , -0.0092047 , -0.021068  , ...,  0.010774  ,\n",
       "        -0.01426   ,  0.0037587 ]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project=np.loadtxt(\"projection.txt\")\n",
    "project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project the training, validation and test data onto the column space of this matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = np.delete(train, -1, axis=1)\n",
    "train_ = train_.dot(project)\n",
    "labels = np.delete(train, np.arange(0, 784), axis=1)\n",
    "train_ = np.concatenate((train_, labels), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validate_ = np.delete(validate, -1, axis=1)\n",
    "validate_ = validate_.dot(project)\n",
    "labels = np.delete(validate, np.arange(0, 784), axis=1)\n",
    "validate_ = np.concatenate((validate_, labels), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ = np.delete(test, -1, axis=1)\n",
    "test_ = test_.dot(project)\n",
    "labels = np.delete(test, np.arange(0, 784), axis=1)\n",
    "test_ = np.concatenate((test_, labels), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Training Error when k is equal to 1 is 0.0\n",
      "The Training Error when k is equal to 3 is 0.16049999999999998\n",
      "The Training Error when k is equal to 5 is 0.1945\n",
      "The Training Error when k is equal to 9 is 0.23050000000000004\n",
      "The Training Error when k is equal to 15 is 0.257\n",
      "282.2208981513977\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "len = train_.shape[0]\n",
    "ks = [1, 3, 5, 9, 15]\n",
    "for k in ks:\n",
    "    correct = []\n",
    "    for i in range(len):\n",
    "        correct.append(knn(train_, train_, i, k))\n",
    "    print('The Training Error when k is equal to ' + str(k) + ' is ' + str(1 - np.mean(correct)))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Validation Error when k is equal to 1 is 0.31999999999999995\n",
      "The Validation Error when k is equal to 5 is 0.29900000000000004\n",
      "The Validation Error when k is equal to 9 is 0.30200000000000005\n",
      "The Validation Error when k is equal to 15 is 0.28900000000000003\n",
      "115.27900719642639\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "len = validate_.shape[0]\n",
    "ks = [1, 5, 9, 15]\n",
    "for k in ks:\n",
    "    correct = []\n",
    "    for i in range(len):\n",
    "        correct.append(knn(train_, validate_, i, k))\n",
    "    print('The Validation Error when k is equal to ' + str(k) + ' is ' + str(1 - np.mean(correct)))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Test Error when k is equal to 1 is 0.29600000000000004\n",
      "28.491159200668335\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "len = test_.shape[0]\n",
    "correct = []\n",
    "for i in range(len):\n",
    "    correct.append(knn(train_, test_, i, 15))\n",
    "print('The Test Error when k is equal to 1 is ' + str(1 - np.mean(correct)))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary:\n",
    "### Part 1 without Projections\n",
    "| k | Train Errors | Validation Errors |\n",
    "| --- | --- | --- |\n",
    "| 1 | 0.0 | 0.082 |\n",
    "| 5 | 0.0565 | 0.095 |\n",
    "| 9 | 0.0685 | 0.103 |\n",
    "| 15 | 0.0925 | 0.108 |\n",
    "\n",
    "* Since $k=1$ performs the best on validation, I calculated the test error for k = 1, and it is $0.094$\n",
    "\n",
    "### Part 2 with Projections\n",
    "| k | Train Errors | Validation Errors |\n",
    "| --- | --- | --- |\n",
    "| 1 | 0.0 | 0.32 |\n",
    "| 5 | 0.1945 | 0.299 |\n",
    "| 9 | 0.2305 | 0.302 |\n",
    "| 15 | 0.257 | 0.289 |\n",
    "\n",
    "* Since $k=15$ performs the best on validation, I calculated the test error for k = 15, and it is $0.296$\n",
    "\n",
    "### How is the classiﬁcation accuracy aﬀected by projection?\n",
    "* The classiﬁcation accuracy with projection $went down$, because the number of x variables went down from 784 to 20. \n",
    "\n",
    "### How does the running time change on projected data?\n",
    "| Runtime | Train Errors (k = 1, 3, 5, 9, 15) | Validation Errors (k = 1, 5, 9, 15) | Test Error (k = 1 or 15)|\n",
    "| --- | --- | --- | --- |\n",
    "| without projection | 304.971 | 133.117 | 30.797|\n",
    "| with projection | 282.221 | 115.279 |28.491 |\n",
    "\n",
    "* The running time $decreases$ on projected data, because there are less columns put into the calculation of Euclidean distance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
